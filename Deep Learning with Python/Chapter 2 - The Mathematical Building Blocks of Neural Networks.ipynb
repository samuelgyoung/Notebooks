{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>A first look at a neural network</h1>\n",
    "\n",
    "The problem we’re trying to solve here is to classify grayscale images of handwrit- ten digits (28 × 28 pixels) into their 10 categories (0 through 9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 1.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting h5py (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/47/e0d58be6f292684a4541d10b1da953542ff679f3ffc6096bee73634832b1/h5py-2.10.0-cp27-cp27m-macosx_10_6_intel.whl (2.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.9MB 389kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from keras)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/21/56/4bcec5a8d9503a87e58e814c4e32ac2b32c37c685672c30bc8c54c6e478a/Keras_Applications-1.0.8.tar.gz (289kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.9.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/09/96/84cf406fe7d589f3dba9fc0f737e65985a3526c6d8c783f02d4b5a10825d/numpy-1.16.6-cp27-cp27m-macosx_10_9_x86_64.whl (13.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.9MB 82kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/ac/d66d66e98b572559028ddbcd47df341a467ee438b185fa18f47f0eec8890/Keras_Preprocessing-1.1.1-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/7a/3de1700fb471a6f56353446b4b962a7e4a5baaf24e5e4dec2d91d5f500da/scipy-1.2.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (27.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 27.4MB 41kB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml, keras-applications\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "  Running setup.py bdist_wheel for keras-applications ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/dd/f2/5d/2689b5547f32c4e258c3b7ccbe7f1d0f2afbb84fb01e830792\n",
      "Successfully built pyyaml keras-applications\n",
      "Installing collected packages: numpy, h5py, pyyaml, keras-applications, keras-preprocessing, scipy, keras\n",
      "  Found existing installation: numpy 1.8.0rc1\n",
      "\u001b[31m    DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n",
      "    Uninstalling numpy-1.8.0rc1:\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 778, in install\n",
      "    requirement.uninstall(auto_confirm=True)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 754, in uninstall\n",
      "    paths_to_remove.remove(auto_confirm)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_uninstall.py\", line 115, in remove\n",
      "    renames(path, new_path)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/utils/__init__.py\", line 267, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 325, in move\n",
      "    copy2(src, real_dst)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 154, in copy2\n",
      "    copystat(src, dst)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 123, in copystat\n",
      "    os.chflags(dst, st.st_flags)\n",
      "OSError: [Errno 1] Operation not permitted: '/var/folders/8n/vtl9dj9n6jx2mkbb_l8sh5kw0000gn/T/pip-QPl0XU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info'\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#INSTALL THE PACKAGES\n",
    "\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/a9/d44e012a2491cf4845b5cac79c3c3af5ab95d657c8953e9d6e076bb05f4d/tensorflow-2.1.0-cp27-cp27m-macosx_10_11_x86_64.whl (120.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 120.8MB 9.4kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel; python_version < \"3\" in /Library/Python/2.7/site-packages (from tensorflow)\n",
      "Collecting scipy==1.2.2; python_version < \"3\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/cf/36b77de4ccb1b841acd4c3c03abe38843c63c3a657cedee9e8fb19a02dc8/scipy-1.2.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (27.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 27.4MB 42kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from tensorflow)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/c5/94a66686b86adfb3ef6f34837d0a7cc2efdc995bc39cad64a9b3e103f0d5/tensorboard-2.1.0-py2-none-any.whl (3.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.8MB 304kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from tensorflow)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/59/22/38238cd9b83dd8a857abd7c907b8fe68ceff1611ab3ca5f0e80a5e025956/google_pasta-0.2.0-py2-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting backports.weakref>=1.0rc1; python_version < \"3.4\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/73/c2/9a3229ec0f364b33366b5b58c40fcbcea5f624d2ed6571f78f6699b71f77/grpcio-1.28.1-cp27-cp27m-macosx_10_9_x86_64.whl (2.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.6MB 434kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting functools32>=3.2.3; python_version < \"3\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/60/6ac26ad05857c601308d8fb9e87fa36d0ebf889423f47c3502ef034365db/functools32-3.2.3-2.tar.gz\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting numpy<2.0,>=1.16.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/09/96/84cf406fe7d589f3dba9fc0f737e65985a3526c6d8c783f02d4b5a10825d/numpy-1.16.6-cp27-cp27m-macosx_10_9_x86_64.whl\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/fd/8aaa5c2e1df1c99dbb3679768ea60e94a88053c08b1f3a6d14fbc12f2550/protobuf-3.11.3-cp27-cp27m-macosx_10_9_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 818kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 7.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/ac/d66d66e98b572559028ddbcd47df341a467ee438b185fa18f47f0eec8890/Keras_Preprocessing-1.1.1-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K    100% |████████████████████████████████| 450kB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow)\n",
      "Collecting mock>=2.0.0; python_version < \"3\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/83/72/479a993ffb2a713419741278863db7d5aa995ff0e66dd354a8c38be3ff4f/google_auth-1.14.3-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting futures>=3.1.1; python_version < \"3\" (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 3.0MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.8->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2c/47/e0d58be6f292684a4541d10b1da953542ff679f3ffc6096bee73634832b1/h5py-2.10.0-cp27-cp27m-macosx_10_6_intel.whl\n",
      "Collecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0; python_version < \"3\"->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<4,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/57/2b/26e37a4b034800c960a00c4e1b3d9ca5d7014e983e6e729e33ea2f36426c/certifi-2020.4.5.1-py2.py3-none-any.whl (157kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 7.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 5.4MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: opt-einsum, functools32, gast, termcolor, absl-py, wrapt\n",
      "  Running setup.py bdist_wheel for opt-einsum ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
      "  Running setup.py bdist_wheel for functools32 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/b5/18/32/77a1030457155606ba5e3ec3a8a57132b1a04b1c4f765177b2\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sgyoung/Library/Caches/pip/wheels/b1/c2/ed/d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
      "Successfully built opt-einsum functools32 gast termcolor absl-py wrapt\n",
      "Installing collected packages: numpy, scipy, opt-einsum, futures, grpcio, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, markdown, protobuf, oauthlib, urllib3, chardet, certifi, idna, requests, requests-oauthlib, google-auth-oauthlib, werkzeug, absl-py, tensorboard, google-pasta, backports.weakref, astor, functools32, gast, termcolor, wrapt, keras-preprocessing, tensorflow-estimator, h5py, keras-applications, funcsigs, mock, tensorflow\n",
      "  Found existing installation: numpy 1.8.0rc1\n",
      "\u001b[31m    DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n",
      "    Uninstalling numpy-1.8.0rc1:\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 778, in install\n",
      "    requirement.uninstall(auto_confirm=True)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 754, in uninstall\n",
      "    paths_to_remove.remove(auto_confirm)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_uninstall.py\", line 115, in remove\n",
      "    renames(path, new_path)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/utils/__init__.py\", line 267, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 325, in move\n",
      "    copy2(src, real_dst)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 154, in copy2\n",
      "    copystat(src, dst)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 123, in copystat\n",
      "    os.chflags(dst, st.st_flags)\n",
      "OSError: [Errno 1] Operation not permitted: '/var/folders/8n/vtl9dj9n6jx2mkbb_l8sh5kw0000gn/T/pip-Vt8IZs-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info'\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_images and train_labels form the training set, the data that the model will learn from. The model will then be tested on the test set, test_images and test_labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9. The images and labels have a one-to-one correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we’ll feed the neural network the training data, train_images and train_labels. The network will then learn to associate images and labels. Finally, we’ll ask the network to produce predictions for test_images, and we’ll verify whether these predictions match the labels from test_labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s build the network.\n",
    "\n",
    "<h2>The network architecture</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,))) \n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our network consists of a sequence of two Dense layers, which are densely connected (also called fully connected) neural layers. The second (and last) layer is a 10-way softmax layer, which means it will return an array of 10 probability scores (sum- ming to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
    "\n",
    "To make the network ready for training, we need to pick three more things, as part\n",
    "of the compilation step:\n",
    "\n",
    " A loss function—How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direc- tion.\n",
    "\n",
    " An optimizer—The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "\n",
    " Metrics to monitor during training and testing—Here, we’ll only care about accu- racy (the fraction of the images that were correctly classified).\n",
    "\n",
    "\n",
    "\n",
    "<h2>The compilation step</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we’ll preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the [0, 1] interval. Previously, our train- ing images, for instance, were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparing the image data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28)) \n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)) \n",
    "test_images = test_images.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparing the labels</h2>\n",
    "\n",
    "We also need to categorically encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train the Network</h2>\n",
    "\n",
    "In Keras is done via a call to the net- work’s fit method—we fit the model to its training data.\n",
    "\n",
    "Two quantities are displayed during training: the loss of the network over the training data, and the accuracy of the network over the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2518 - accuracy: 0.9263\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1040 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0699 - accuracy: 0.9790\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0379 - accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x104712f10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Performance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9782000184059143\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test-set accuracy turns out to be 97.8%—that’s quite a bit lower than the training set accuracy. This gap between training accuracy and test accuracy is an example of overfitting: the fact that machine-learning models tend to perform worse on new data than on their training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data representations for neural networks</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Definitions:</i>\n",
    "\n",
    "tensors : multidimensional Numpy arrays. all current machine-learning systems use tensors as their basic data structure. a tensor is a container for data—almost always numerical data. So, it’s a container for numbers. You may be already familiar with matrices, which are 2D ten- sors: tensors are a generalization of matrices to an arbitrary number of dimensions\n",
    "\n",
    "axis : aka dimension of the data\n",
    "\n",
    "rank : The number of axes of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Scalars (0D tensors)</h2>\n",
    "\n",
    "A tensor that contains only one number is called a scalar.\n",
    "\n",
    " You can display the number of axes of a Numpy tensor via the ndim attribute; a sca- lar tensor has 0 axes (ndim == 0).\n",
    " \n",
    " Here’s a Numpy scalar:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Vectors (1D tensors)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " x = np.array([12, 3, 6, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Matrices (2D tensors)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0], \n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3D tensors and higher-dimensional tensors</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0], \n",
    "               [6, 79, 3, 35, 1],\n",
    "                [7, 80, 4, 36, 2]],\n",
    "                [[5, 78, 2, 34, 0],\n",
    "                 [6, 79, 3, 35, 1],\n",
    "                 [7, 80, 4, 36, 2]],\n",
    "                [[5, 78, 2, 34, 0],\n",
    "                 [6, 79, 3, 35, 1],\n",
    "                 [7, 80, 4, 36, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Key attributes of tensors</h2>\n",
    "\n",
    "1. Number of axes (rank)\n",
    "2. Shape — This is a tuple of integers that describes how many dimensions the ten- sor has along each axis. For instance, the previous matrix example has shape (3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape with a single element, such as (5,), whereas a scalar has an empty shape, ()\n",
    "3. Data type (usually called dtype in Python libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So what we have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 8 integers. Each such matrix is a grayscale image, with coeffi- cients between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s display the fourth digit in this 3D tensor, using the library Matplotlib (part of the standard scientific Python suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(digit, cmap=plt.cm.binary) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55,\n",
       "        148, 210, 253, 253, 113,  87, 148,  55,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 232,\n",
       "        252, 253, 189, 210, 252, 252, 253, 168,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  57, 242, 252,\n",
       "        190,  65,   5,  12, 182, 252, 253, 116,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 183,\n",
       "         14,   0,   0,  92, 252, 252, 225,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 132, 253, 252, 146,  14,\n",
       "          0,   0,   0, 215, 252, 252,  79,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 126, 253, 247, 176,   9,   0,\n",
       "          0,   8,  78, 245, 253, 129,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  16, 232, 252, 176,   0,   0,   0,\n",
       "         36, 201, 252, 252, 169,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  22, 252, 252,  30,  22, 119, 197,\n",
       "        241, 253, 252, 251,  77,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  16, 231, 252, 253, 252, 252, 252,\n",
       "        226, 227, 252, 231,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  55, 235, 253, 217, 138,  42,\n",
       "         24, 192, 252, 143,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         62, 255, 253, 109,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        106, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         45, 255, 253,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 218, 252,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  96, 252, 189,  42,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  14, 184, 252, 170,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  14, 147, 252,  42,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Manipulating tensors in Numpy</h2>\n",
    "\n",
    "<h3>Slicing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we selected a specific digit alongside the first axis using the syntax train_images[i]. Selecting specific elements in a tensor is called tensor slicing.\n",
    "\n",
    "Let’s look at the tensor-slicing operations you can do on Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#The following example selects digits #10 to #100 (#100 isn’t included) \n",
    "#and puts them in an array of shape (90, 28, 28):\n",
    "\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that : is equivalent to selecting the entire axis:\n",
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also equivalent\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For instance, in order to select 14 × 14 pixels \n",
    "#in the bottom-right corner of all images, you do this:\n",
    "\n",
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It’s also possible to use negative indices\n",
    "\n",
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Batches</h2>\n",
    "\n",
    "In general, the first axis (axis 0, because indexing starts at 0) in all data tensors you’ll come across in deep learning will be the samples axis.\n",
    "\n",
    "deep-learning models don’t process an entire dataset at once; rather, they break the data into small batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s the next batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering such a batch tensor, the first axis (axis 0) is called the batch axis or batch dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Real-world examples of data tensors</h2>\n",
    "\n",
    "Usually one of these types:\n",
    "\n",
    "1. Vector data—2D tensors of shape(samples,features)\n",
    "2. Timeseries data or sequence data—3D tensors of shape (samples, timesteps, features)\n",
    "3. Images—4D tensors of shape(samples,height,width,channels)or(samples, channels, height, width)\n",
    "4. Video —5D tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tensor Operations</h2>\n",
    "\n",
    "All transformations learned by deep neural networks can be reduced to a handful of tensor operations applied to tensors of numeric data. For instance, it’s possible to add tensors, multiply tensors, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Element-wise operations</h3>\n",
    "\n",
    "The relu operation and addition are element-wise operations: operations that are applied independently to each entry in the tensors being considered. This means these operations are highly amenable to massively parallel implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Broadcasting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to match the shape of the larger tensor. Broadcasting consists of two steps:\n",
    "\n",
    "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "\n",
    "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor dot</h3>\n",
    "\n",
    "The most common, most useful tensor operation. Contrary to element-wise operations, it combines entries in the input tensors.\n",
    "\n",
    "dot uses a different syntax in TensorFlow, but in both Numpy and Keras it’s done using the standard dot operator:\n",
    "\n",
    "import numpy as np z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor reshaping</h3>\n",
    "\n",
    "Example:\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "\n",
    "Reshaping a tensor means rearranging its rows and columns to match a target shape.\n",
    "\n",
    "Naturally, the reshaped tensor has the same total number of coefficients as the initial tensor. Reshaping is best understood via simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0., 1.], \n",
    "              [2., 3.],\n",
    "              [4., 5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of reshaping that’s commonly encountered is transposition. Transposing a matrix means exchanging its rows and its columns, so that x[i, :] becomes x[:, i]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((300, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The engine of neural networks:\n",
    "gradient-based optimization</h3>\n",
    "\n",
    "1 Draw a batch of training samples x and corresponding targets y.\n",
    "\n",
    "2 Run the network on x (a step called the forward pass) to obtain predictions y_pred.\n",
    "\n",
    "3 Compute the loss of the network on the batch, a measure of the mismatch\n",
    "between y_pred and y.\n",
    "\n",
    "4 Update all weights of the network in a way that slightly reduces the loss on this\n",
    "batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
