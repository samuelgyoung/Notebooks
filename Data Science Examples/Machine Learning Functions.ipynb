{
    "nbformat_minor": 1, 
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "name": "python2-spark21", 
            "display_name": "Python 2 with Spark 2.1"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "def SVD(dependent, target):\n    #Singular Value Decomposition\n    import matplotlib.pyplot as pit\n    import numpy as np\n    from sklearn.preprocessing import scale \n    from scipy.linalg import svd\n    \n    x = dependent\n    y = target\n    \n    # Proceed By Scaling the x varible w.r.t its mean\n    # with_mean=False,with_std=False <- Data not Measured the same in dependent\n    # with_mean=True,with_std=False <- Data Measured the same in dependent\n    \n    x_s = scale(x,with_mean=False,with_std=False,axis=0)\n    \n    # Decompose the matrix using SW technique.We will use SVO implementation in scipy.\n    U,S,V = svd(x_s,full_matrices=False)\n    \n    x_t = U[:,:2]\n    \n    # Finally we plot the datasets with the reduced components.\n    plt.figure(1)\n    plt.scatter(x_t[:,0],x_t[:,1],c=y)\n    plt.xlabel(\"Component 1\") \n    plt.ylabel(\"Component 2\") \n    plt.show()", 
            "outputs": [], 
            "cell_type": "code"
        }
    ]
}